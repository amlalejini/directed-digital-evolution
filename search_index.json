[["index.html", "Supplemental Material for Directed Digital Evolution Project Chapter 1 Introduction", " Supplemental Material for Directed Digital Evolution Project Alexander Lalejini, Emily Dolson, Anya E. Vostinar, and Luis Zaman 2022-03-31 Chapter 1 Introduction Hello world! "],["software-availability.html", "Chapter 2 Software availability", " Chapter 2 Software availability The source code used to implement out experiments as well as the code for performing data analyses and generating visualizations are publicly available on GitHub: https://github.com/amlalejini/directed-digital-evolution. Additionally, our GitHub repository is archived via Zenodo (???). "],["data-availability.html", "Chapter 3 Data availability", " Chapter 3 Data availability The data produced by the experiments reported in our manuscript are archived and publicly available on the Open Science Framework (Lalejini 2022) at https://osf.io/zn63x/. References "],["compiling-and-running-our-experiments.html", "Chapter 4 Compiling and running our experiments 4.1 Manual 4.2 Docker", " Chapter 4 Compiling and running our experiments Here, we provide a brief guide to compiling and running our experiments. Please file an issue if something is unclear or does not work. We document two methods of compiling and running our experiments: Manually downloading the repository and dependencies, compiling, and running on your local machine Running inside of a Docker container 4.1 Manual These instructions assume a Ubuntu-flavored Linux operating system, and they should mostly work for MacOS too (but no promises there). Otherwise, we recommend using our Docker image or using a virtual machine running linux. You will need a C++ compiler capable of compiling C++17 code. For example, Im using: g++ (Ubuntu 11.2.0-7ubuntu2) 11.2.0 Next, clone this repository from GitHub. git clone https://github.com/amlalejini/directed-digital-evolution After cloning, cd into the freshly cloned repository, and run git submodule update --init --recursive This should download all of the third-party dependencies (into the third-party/ directory) necessary for compiling our experiment software. From here, you should be able to compile the experiment source code by running make in the root directory of the repository. Edit the PROJECT, MAIN_CPP, and THREADING variables at the top of the Makefile to configure which experiment youre compiling and whether you compile with threading (note some data tracking will not work with threading enabled). The configuration files used for each experiment can be found inside the particular experiments associated directory (experiments/[experiment-name]/hpcc/config/). 4.2 Docker You can use the Dockerfile in our repository to build a docker image locally, or you can pull the latest docker image from this DockerHub repository: amlalejini/directed-digital-evolution. To pull the latest docker image from DockerHub, run docker pull amlalejini/directed-digital-evolution Regardless of whether you built the image locally or pulled it from DockerHub, it should contain: all of the requisite dependencies to run our experiment software and analysis scripts all of our project source code (from our GitHub repository) To run the container interactively: docker run -it --entrypoint bash amlalejini/directed-digital-evolution "],["digital-organisms.html", "Chapter 5 Digital Organisms 5.1 Virtual Hardware Components 5.2 Instruction set 5.3 Ancestral genomes", " Chapter 5 Digital Organisms Here, we provide supplemental information about the digital organisms used in our experiments. 5.1 Virtual Hardware Components Each digital organism is defined by a sequence of program instructions (its genome) and a set of virtual hardware components used to interpret and express those instructions. The virtual hardware and genetic representation used in this work extends that of (Dolson, Lalejini, and Ofria 2019,hernandez_what_2022). The virtual hardware includes the following components: Instruction pointer: A marker that indicates the position in the genome currently being executed. Instructions may influence how the instruction pointer moves through the genome (e.g., if instructions). Memory registers: A digital organism has access to 16 memory registers (abbreviated as REG-0 through REG-15) for performing computations. Each register can store a single floating point value, and instructions can read and write to registers. Registers are initialized with values corresponding to their register ID (e.g., REG-0 is initialized with the value 0). Memory stacks: Each digital organism has access to 16 memory stacks (abbreviated as STK-0 through STK-15). Instructions can push values onto a stack and pop them off later. Input and output buffers: Each digital organism has a read-only input buffer and a write-only output buffer. Digital organisms could execute instructions to read values from their input buffer and execute instructions to write values to their output buffer. When an organism is born, their output buffer is empty, and we initialize their input buffer with 2 values (as all computational tasks used in this work had a maximum of 2 inputs), each value ranging between 0 and 100000000. Input buffers are accessed in order and are circular; that is, when an instruction reads from the input buffer, it reads the next value (starting with the first) and wraps around to the beginning after reading the last value in the buffer. To perform a computational task (e.g., those in Table 1 of our manuscript), an organism must load values from their input buffer into their memory registers, compute the requisite function, and output the result to their output buffer. During an organisms lifetime, we analyzed their output buffer to determine if they performed any of the designated computational tasks. Scopes: Each digital organism could make use of 16 `scopes'' plus a global scope, making 17 possible scopes. Below is an introduction to scopes as a mechanism for modularity, which is adapted from [@dolson_exploring_2019]: &gt; In software development, the _scope_ of a variable specifies the region of code in which that element may be used. In a sense, a scope is like a programmatic membrane, capable of encapsulating programmatic elements (e.g., variables, functions, _et cetera_) and allowing regions to be looped through or skipped entirely. Our genetic representation gives programs control over instruction- and memory-scoping, which allows programs to manage flow control and variable lifetime. &gt; &gt; In our genetic representation, scopes provide the backbone on top of which all of the other modularity-promoting features, such as loops and functions, are built. All instructions in a program exist within a scope, be it the default outermost scope or one of the 16 other available scopes that can be accessed via instructions. The 16 inner scopes have a hierarchy to them, such that higher-numbered scopes are always nested inside lower-numbered scopes. &gt; &gt; Starting at the beginning of a program, all instructions before the first change of scope are in the outermost (global) scope. After a scope-changing instruction occurs in the program, subsequent instructions are added to the new scope until another scope-changing instruction is encountered, and so on. These scopes are ordered numerically. Higher-numbered scopes are always nested inside lower-numbered scopes. Scopes can be exited with thebreakinstruction or by any instruction that moves control to a lower-numbered scope. &gt; &gt; Scopes are also the foundation of program modules (functions) in our genetic representation. Thedefineinstruction allows the program to put instructions into a scope and associate the contents of that scope with one of 16 possible function names. Later, if that function is called (using thecall` instruction), the program enters the scope in which that function was defined and executes the instructions within that scope in sequence, including any internal (nested) scopes. &gt; &gt; Similarly, scopes are the foundation of loops. Two kinds of loops exist in the instruction set used here: while loops and countdown loops. Loops of both types have a corresponding scope, which contains the sequence of instructions that make up the body of the loop. Both types of loops repeat their body (i.e., the contents of their associated scope) until the value in an argument-specified register is 0. Countdown loops automatically decrement this register by one on every iteration. When any instruction is encountered that would cause the program to leave the current scope, the current iteration is ended and the next one begins. Self-replication machinery: A digital organisms virtual hardware tracks how many instructions an organism has copied (regardless of how many of those copies are erroneous), and prevents an organism from dividing until it has copied at least as many instructions as are in its genome. 5.2 Instruction set The table below gives the instruction set used by digital organisms in our digital directed evolution experiments. Note that each instruction in an organisms genome contains three arguments, which may modify the effect of the instruction. Instruction arguments are limited to the values 0 through 15, and arguments are used to specify any of the following: registers, raw values, or scopes. In an instructions description, we denote argument values as ARG-0, ARG-1, and ARG-2 where ARG-0 represents the value of the first argument for the instruction and so on. Instructions that operate on bitstrings (e.g., Not and Nand) operate on the underlying bit representation of the values stored in the relevant registers. When the result of a binary (true/false) comparison is stored in a register (e.g., from a TestEqu instruction), false is stored as 0 and true is stored as 1. We excluded the following instructions from our genetic programming experiment: CopyInst, DivideSelf. Instruction # Arguments New scope Description Nop 0 None No operation Inc 1 None REG[ARG-0] = REG[ARG-0] + 1 Dec 1 None REG[ARG-0] = REG[ARG-0] - 1 Not 1 None REG[ARG-0] = !REG[ARG-0] SetReg 2 None REG[ARG-0] = ARG-1 Add 3 None REG[ARG-2] = REG[ARG-0] + REG[ARG-1] Sub 3 None REG[ARG-2] = REG[ARG-0] - REG[ARG-1] Mult 3 None REG[ARG-2] = REG[ARG-0] * REG[ARG-1] Div 3 None REG[ARG-2] = REG[ARG-0] / REG[ARG-1] Mod 3 None REG[ARG-2] = REG[ARG-0] % REG[ARG-1] Nand 3 None REG[ARG-2] = !REG[ARG-0] &amp; REG[ARG-1] TestEqu 3 None REG[ARG-2] = REG[ARG-0] == REG[ARG-1] TestNEqu 3 None REG[ARG-2] = REG[ARG-0] != REG[ARG-1] TestLess 3 None REG[ARG-2] = REG[ARG-0] \\(&lt;\\) REG[ARG-1] If 2 ARG-1 If REG[ARG-0] != 0, continue to SCOPE[ARG-1]; else, skip SCOPE[ARG-1] While 2 ARG-1 Repeat the contents of SCOPE[ARG-1] until REG[ARG-0] equals 0 Countdown 2 ARG-1 Repeat the contents of SCOPE[ARG-1], decrementing REG[ARG-0] each time, until REG[ARG-0] equals 0 Break 1 None Break out of SCOPE[ARG-0] Scope 1 ARG-0 Enter SCOPE[ARG-0] Define 2 ARG-1 Define this position as the starting point of function ARG-0 with its contents defined as SCOPE[ARG-1]. The function body is skipped after being defined; when called, the function automatically returns when SCOPE[ARG-1] is exited. Call 1 None Call function ARG-0, which must already have been defined by a instruction. Push 2 None Push REG[ARG-0] onto STK[ARG-1] Pop 2 None Pop top value of STK[ARG-0] onto REG[ARG-1] CopyVal 2 None REG[ARG-1] = REG[ARG-0] ScopeReg 1 None Backup the value in REG[ARG-0]. When the current scope is exited, it will be restored. CopyInst 0 None Copy the next instruction (for self-replication). GetLen 1 None Set REG[ARG-0] to the current genome length. DivideSelf 0 None If the requisite number of instructions have been copied, trigger division (producing an offspring). Input 1 None Load the next input value into REG[ARG-0] Output 1 None Append REG[ARG-0] to the output buffer 5.3 Ancestral genomes The files containing the ancestral genome used to seed initial populations for each experiment are included in the GitHub repository (???). Each ancestral genome is 100 instructions long. The ancestral genome used for our genetic programming experiments does nothing except define a root scope. The ancestral genome used for our directed evolution experiments copies itself and then divides, producing an offspring. 5.3.1 Ancestral genome for genetic programming experiment Scope 0 Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop 5.3.2 Ancestral genome for directed evolution experiments Scope 0 Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop Nop GetLen 15 Countdown 15 1 CopyInst 0 Scope 0 DivideSelf References "],["conventional-genetic-programming-experiment.html", "Chapter 6 Conventional genetic programming experiment 6.1 Overview 6.2 Analysis dependencies 6.3 Setup 6.4 Number of successful replicates 6.5 Final task coverage 6.6 Generation 2,000 task coverage 6.7 Population-level task coverage 6.8 Generations elapsed before a solution evolves", " Chapter 6 Conventional genetic programming experiment Data analyses for our conventional evolutionary computing experiment. 6.1 Overview experiment_slug &lt;- &quot;2021-11-15-ec&quot; working_directory &lt;- paste0(&quot;experiments/&quot;,experiment_slug,&quot;/analysis/&quot;) 6.2 Analysis dependencies Load all required R libraries library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.8 ## v tidyr 1.2.0 v stringr 1.4.0 ## v readr 2.1.2 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(ggplot2) library(cowplot) library(RColorBrewer) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) These analyses were knit with the following environment: print(version) ## _ ## platform x86_64-pc-linux-gnu ## arch x86_64 ## os linux-gnu ## system x86_64, linux-gnu ## status ## major 4 ## minor 1.3 ## year 2022 ## month 03 ## day 10 ## svn rev 81868 ## language R ## version.string R version 4.1.3 (2022-03-10) ## nickname One Push-Up 6.3 Setup Load experiment summary data. exp_summary_data_loc &lt;- paste0(working_directory,&quot;data/experiment_summary.csv&quot;) exp_summary_data &lt;- read.csv(exp_summary_data_loc, na.strings=&quot;NONE&quot;) exp_summary_data$SELECTION_METHOD &lt;- factor( exp_summary_data$SELECTION_METHOD, levels=c( &quot;elite&quot;, &quot;elite-10&quot;, &quot;tournament&quot;, &quot;lexicase&quot;, &quot;non-dominated-elite&quot;, &quot;non-dominated-tournament&quot;, &quot;random&quot;, &quot;none&quot; ), labels=c( &quot;elite&quot;, &quot;elite-10&quot;, &quot;tourn&quot;, &quot;lex&quot;, &quot;nde&quot;, &quot;ndt&quot;, &quot;random&quot;, &quot;none&quot; ) ) Load time series data. time_series_data_loc &lt;- paste0(working_directory,&quot;data/pop_snapshot_time_series.csv&quot;) time_series_data &lt;- read.csv(time_series_data_loc, na.strings=&quot;NONE&quot;) get_sel &lt;- function(seed) { return(filter(exp_summary_data, SEED==seed)$SELECTION_METHOD) } solution_evolved_fun &lt;- function(seed, update) { d &lt;- filter(exp_summary_data, SEED==seed) return(update==d$update &amp;&amp; d$max_fit_is_solution==&quot;1&quot;); } time_series_data$SELECTION_METHOD &lt;- mapply( get_sel, time_series_data$SEED ) time_series_data$solution_evolved &lt;- mapply( solution_evolved_fun, time_series_data$SEED, time_series_data$update ) time_series_data$SELECTION_METHOD &lt;- as.factor( time_series_data$SELECTION_METHOD ) exp_data_gen_2000 &lt;- filter(time_series_data, update==2000) Miscellaneous setup. # Configure our default graphing theme theme_set(theme_cowplot()) # Palette cb_palette &lt;- &quot;Set2&quot; # Create a directory to store plots plot_directory &lt;- paste0(working_directory, &quot;plots/&quot;) dir.create(plot_directory, showWarnings=FALSE) # Order selection schemes. selection_method_breaks &lt;- c(&quot;elite&quot;, &quot;elite-10&quot;, &quot;tourn&quot;, &quot;lex&quot;, &quot;nde&quot;, &quot;random&quot;, &quot;none&quot;) selection_method_labels &lt;- c(&quot;ELITE&quot;, &quot;TOP-10&quot;, &quot;TOURN&quot;, &quot;LEX&quot;, &quot;NDE&quot;, &quot;RAND&quot;, &quot;NONE&quot;) 6.4 Number of successful replicates We considered a run to be successful if it produced a program capable of performing all 22 tasks during evaluation. ggplot( filter(exp_summary_data, max_fit_is_solution==&quot;1&quot;), aes(x=SELECTION_METHOD, fill=SELECTION_METHOD) ) + geom_bar() + geom_text( stat=&quot;count&quot;, mapping=aes(label=..count..), position=position_dodge(0.9), vjust=0 ) + scale_y_continuous( limits=c(0, 50), breaks=seq(0,50,10) ) + scale_x_discrete( name=&quot;Selection Method&quot;, limits=selection_method_breaks, breaks=selection_method_breaks, labels=selection_method_labels ) + scale_fill_brewer( palette=cb_palette ) + scale_color_brewer( palette=cb_palette ) + ylab(&quot;Successful replicates&quot;) + theme(legend.position = &quot;none&quot;) ggsave( paste0(plot_directory, &quot;2021-11-15-num-solutions.pdf&quot;) ) ## Saving 7 x 5 in image 6.5 Final task coverage Task coverage after 55,000 generations of evolution. max_task_cov_fig &lt;- ggplot( exp_summary_data, aes( x=SELECTION_METHOD, y=max_fit_aggregate_score, fill=SELECTION_METHOD ) ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust=1.5 ) + geom_point( mapping=aes(color=SELECTION_METHOD), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( name=&quot;Task Coverage&quot;, limits=c(-0.5,22.5), breaks=seq(0,22,2) ) + scale_x_discrete( name=&quot;Selection Method&quot;, breaks=selection_method_breaks, labels=selection_method_labels ) + scale_fill_brewer( palette=cb_palette ) + scale_color_brewer( palette=cb_palette ) + theme( legend.position=&quot;none&quot;, axis.text = element_text(size = 8), axis.title = element_text(size=10) ) max_task_cov_fig ggsave( plot=max_task_cov_fig, filename=paste0(plot_directory, &quot;2021-11-15-ec-performance.pdf&quot;), height=3, width=4 ) # save_plot( # filename=paste0(plot_directory, &quot;2021-11-15-ec-performance-2.pdf&quot;), # plot=max_task_cov_fig, # base_height=6, # base_asp=2.5 # ) Statistical results: kruskal.test( formula=max_fit_aggregate_score~SELECTION_METHOD, data=exp_summary_data ) ## ## Kruskal-Wallis rank sum test ## ## data: max_fit_aggregate_score by SELECTION_METHOD ## Kruskal-Wallis chi-squared = 332.52, df = 6, p-value &lt; 2.2e-16 # Kruskal-wallis is significant, so we do a post-hoc wilcoxon rank-sum. pairwise.wilcox.test( x=exp_summary_data$max_fit_aggregate_score, g=exp_summary_data$SELECTION_METHOD, p.adjust.method=&quot;bonferroni&quot;, ) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: exp_summary_data$max_fit_aggregate_score and exp_summary_data$SELECTION_METHOD ## ## elite elite-10 tourn lex nde random ## elite-10 0.0087 - - - - - ## tourn 1.8e-14 &lt; 2e-16 - - - - ## lex &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 - - - ## nde &lt; 2e-16 &lt; 2e-16 1.7e-15 &lt; 2e-16 - - ## random &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 - ## none &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 0.8360 ## ## P value adjustment method: bonferroni 6.6 Generation 2,000 task coverage Task coverage after 2,000 generations (i.e., the number of cycles runin the directed evolution experiments) ggplot( exp_data_gen_2000, aes( x=SELECTION_METHOD, y=max_org_task_coverage, fill=SELECTION_METHOD ) ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8, adjust=1.5 ) + geom_point( mapping=aes(color=SELECTION_METHOD), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_y_continuous( name=&quot;Task Coverage&quot;, limits=c(-0.5,22.5), breaks=seq(0,22,2) ) + scale_x_discrete( name=&quot;Selection Method&quot;, breaks=selection_method_breaks, labels=selection_method_labels ) + scale_fill_brewer( palette=cb_palette ) + scale_color_brewer( palette=cb_palette ) + theme( legend.position=&quot;none&quot;, axis.text = element_text(size = 8), axis.title = element_text(size=10) ) ggsave( filename=paste0(plot_directory, &quot;max_aggregate_score_gen_2000.pdf&quot;), height=3, width=4 ) Statistical results: kruskal.test( formula=max_org_task_coverage~SELECTION_METHOD, data=exp_data_gen_2000 ) ## ## Kruskal-Wallis rank sum test ## ## data: max_org_task_coverage by SELECTION_METHOD ## Kruskal-Wallis chi-squared = 322.54, df = 6, p-value &lt; 2.2e-16 # Kruskal-wallis is significant, so we do a post-hoc wilcoxon rank-sum. pairwise.wilcox.test( x=exp_data_gen_2000$max_org_task_coverage, g=exp_data_gen_2000$SELECTION_METHOD, p.adjust.method=&quot;bonferroni&quot;, ) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: exp_data_gen_2000$max_org_task_coverage and exp_data_gen_2000$SELECTION_METHOD ## ## elite elite-10 tourn lex nde random ## elite-10 1.4e-09 - - - - - ## tourn 0.0013 1.9e-14 - - - - ## lex &lt; 2e-16 7.3e-15 &lt; 2e-16 - - - ## nde 9.8e-14 2.3e-16 2.7e-11 &lt; 2e-16 - - ## random &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 - ## none &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 1.0000 ## ## P value adjustment method: bonferroni 6.7 Population-level task coverage Task coverage across entire population after 55,000 generations of evolution. ggplot( exp_summary_data, aes( x=SELECTION_METHOD, y=population_num_tasks_covered, fill=SELECTION_METHOD ) ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8 ) + geom_point( mapping=aes(color=SELECTION_METHOD), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_fill_brewer( palette=&quot;Set2&quot; ) + scale_color_brewer( palette=&quot;Set2&quot; ) + theme( legend.position=&quot;none&quot; ) ggsave( paste0(plot_directory, &quot;population_num_tasks_covered.pdf&quot;) ) ## Saving 7 x 5 in image 6.8 Generations elapsed before a solution evolves Runs where no solution evolved are in gray and plotted as unsolved. unfinished_data &lt;- filter(exp_summary_data, max_fit_is_solution==&quot;0&quot;) unfinished_data$graph_update &lt;- 60000 ggplot( filter(exp_summary_data, max_fit_is_solution==&quot;1&quot;), aes( x=SELECTION_METHOD, y=update ) ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8 ) + geom_point( position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_point( data = unfinished_data, mapping=aes( x=SELECTION_METHOD, y=graph_update ), color=&quot;gray&quot;, position = position_jitter(width = .15, height=1000), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + # scale_fill_brewer( # palette=&quot;Set2&quot;, # breaks=selection_method_breaks, # labels=selection_method_labels # ) + # scale_color_brewer( # palette=&quot;Set2&quot;, # breaks=selection_method_breaks, # labels=selection_method_labels # ) + scale_y_continuous( name=&quot;Generation first solution evolved&quot;, limits=c(0, 65000), breaks=c(0, 10000, 20000, 30000, 40000, 50000, 60000), labels=c(&quot;0&quot;, &quot;10000&quot;, &quot;20000&quot;, &quot;30000&quot;, &quot;40000&quot;, &quot;50000&quot;, &quot;Unsolved&quot;) ) + theme( legend.position=&quot;none&quot; ) ## Warning: Groups with fewer than two data points have been dropped. ggsave( paste0(plot_directory, &quot;updates_until_solution.pdf&quot;) ) ## Saving 7 x 5 in image ## Warning: Groups with fewer than two data points have been dropped. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
